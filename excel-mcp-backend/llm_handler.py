import os
import numpy as np
import json
import pandas as pd
from json import JSONEncoder

os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'
os.environ['MKL_THREADING_LAYER'] = 'GNU'

# Classe personnalis√©e pour la s√©rialisation JSON des objets pandas Timestamp
class PandasJSONEncoder(JSONEncoder):
    def default(self, obj):
        if hasattr(obj, 'isoformat'):
            return obj.isoformat()
        elif hasattr(obj, 'to_dict'):
            return obj.to_dict()
        elif hasattr(obj, 'tolist'):
            return obj.tolist()
        elif pd.isna(obj):
            return None
        return JSONEncoder.default(self, obj)

#Storage
os.environ["TRANSFORMERS_CACHE"] = "/workspace/model_cache"
os.environ["HF_HOME"] = "/workspace/model_cache"
os.environ["VLLM_CACHE_DIR"] = "/workspace/model_cache/vllm"

import logging
import threading
import torch
from typing import Dict, Any, List, Optional, Tuple, Union
import tempfile
import pandas as pd
import re
import io
import sys
import contextlib
import base64
from transformers import AutoTokenizer
import json
# Nouvelle importation pour VLLM
from vllm import LLM, SamplingParams

# Importations pour les visualisations
import matplotlib
matplotlib.use('Agg')  # Utilisation du backend non-interactif
import matplotlib.pyplot as plt
import seaborn as sns

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Variables globales pour le mod√®le LLM
LLM_MODEL = None
LLM_TOKENIZER = None
LLM_LOADING = False
LLM_ERROR = None
LLM_AVAILABLE = False

# Configuration du mod√®le
MODEL_NAME = "Phind/Phind-CodeLlama-34B-v2"  # Votre mod√®le pr√©f√©r√©
MODEL_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
MAX_NEW_TOKENS = 2048
TEMPERATURE = 0.1

# Contexte pour les prompts
SYSTEM_PROMPT = """Tu es un assistant d'analyse de donn√©es expert en Python pour pandas et l'extraction de donn√©es pour visualisations. 
Ta t√¢che est de g√©n√©rer du code Python qui r√©pond √† des requ√™tes sur des donn√©es Excel ET extrait les donn√©es structur√©es 
pour des visualisations interactives.

DETECTION D'INTENTION:
1. Si la requ√™te demande explicitement une visualisation (graphique, diagramme, tendance visuelle), ou pourrait b√©n√©ficier d'une repr√©sentation visuelle, tu DOIS extraire les donn√©es structur√©es pour cette visualisation.
2. Si la requ√™te est purement factuelle (somme, comptage simple, statistique unique), tu dois quand m√™me formater les r√©sultats de mani√®re structur√©e.

POUR L'EXTRACTION DE DONN√âES:
- Pour les tendances temporelles ou √©volutions: extrais les paires de valeurs (x,y) dans une liste de dictionnaires.
- Pour les comparaisons entre cat√©gories: extrais les paires (cat√©gorie, valeur) dans une liste de dictionnaires.
- Pour les r√©partitions proportionnelles: extrais les paires (nom, valeur) dans une liste de dictionnaires.
- Pour les statistiques: organise les r√©sultats dans un tableau structur√© avec libell√©s et valeurs.

SP√âCIFICATIONS TECHNIQUES:
- Tu dois TOUJOURS cr√©er une variable sp√©ciale nomm√©e 'visualization_data' qui contient un dictionnaire avec la structure suivante:
{
  "visualization_type": "line"|"bar"|"pie"|"stats",
  "title": "Titre du graphique",
  "data": [ {}, {}, ... ],
  "x_axis": {"key": "nom_cl√©_x", "label": "Libell√© axe X"},
  "y_axis": {"key": "nom_cl√©_y", "label": "Libell√© axe Y"}
}

- Le champ 'visualization_type' doit √™tre l'un des suivants:
  * "line" pour les graphiques lin√©aires (tendances/√©volutions)
  * "bar" pour les diagrammes √† barres (comparaisons)
  * "pie" pour les diagrammes circulaires (r√©partitions)
  * "stats" pour les tableaux de statistiques

- Pour les graphiques lin√©aires et √† barres:
  * La liste 'data' contient des objets avec au moins les cl√©s correspondant aux axes x et y
  * 'x_axis' et 'y_axis' doivent sp√©cifier la cl√© d'acc√®s aux donn√©es ('key') et le libell√© de l'axe ('label')

- Pour les diagrammes circulaires:
  * La liste 'data' contient des objets avec au moins 'name' et 'value'

- Pour les statistiques:
  * La liste 'data' contient des objets avec 'label' et 'value'

EXEMPLE DE STRUCTURE POUR CHAQUE TYPE:
Pour un graphique lin√©aire (√©volution temporelle):
visualization_data = {
  "visualization_type": "line",
  "title": "√âvolution des ventes",
  "data": [
    {"month": "Jan", "sales": 40},
    {"month": "Feb", "sales": 60},
    {"month": "Mar", "sales": 45}
  ],
  "x_axis": {"key": "month", "label": "Mois"},
  "y_axis": {"key": "sales", "label": "Ventes (‚Ç¨)"}
}

G√©n√®re UNIQUEMENT du code Python sans explication, commentaire ou texte suppl√©mentaire.
Le code doit √™tre ex√©cutable directement et imprimer les r√©sultats textuels comme avant pour assurer la compatibilit√©.
Tu dois TOUJOURS d√©finir la variable 'visualization_data' en plus d'imprimer les r√©sultats textuels.

IMPORTANT: N'importe jamais matplotlib ou seaborn.
"""

def check_model_cache():
    """V√©rifie si le mod√®le est d√©j√† en cache"""
    model_cache_path = "/workspace/model_cache/vllm/models/Phind/Phind-CodeLlama-34B-v2"
    if os.path.exists(model_cache_path):
        logger.info(f"‚úÖ Mod√®le trouv√© dans le cache: {model_cache_path}")
        return True
    else:
        logger.info(f"‚ùå Mod√®le non trouv√© dans le cache, t√©l√©chargement n√©cessaire")
        return False

def load_llm_model_background():
    """Charge le mod√®le LLM en arri√®re-plan avec VLLM"""
    global LLM_MODEL, LLM_TOKENIZER, LLM_LOADING, LLM_ERROR, LLM_AVAILABLE
    
    try:
        # V√©rifier si le mod√®le est d√©j√† en cache
        model_cache_path = "/workspace/model_cache/vllm/models/Phind/Phind-CodeLlama-34B-v2"
        cache_exists = os.path.exists(model_cache_path)
        
        logger.info(f"Chargement du mod√®le LLM {MODEL_NAME} avec VLLM... (Cache {'existant' if cache_exists else 'inexistant'})")
        
        # Charger le tokenizer normalement depuis Hugging Face
        LLM_TOKENIZER = AutoTokenizer.from_pretrained(
            MODEL_NAME, 
            trust_remote_code=True,
            cache_dir="/workspace/model_cache"
        )
        
        # Charger le mod√®le avec VLLM - utilise quantification automatique
        LLM_MODEL = LLM(
            model=MODEL_NAME,
            tensor_parallel_size=1,
            trust_remote_code=True,
            dtype="half",
            gpu_memory_utilization=0.85,
            max_model_len=4096,
            quantization="bitsandbytes",
            download_dir="/workspace/model_cache",
        )
        
        logger.info(f"Mod√®le LLM {MODEL_NAME} charg√© avec succ√®s via VLLM sur {MODEL_DEVICE}!")
        LLM_AVAILABLE = True
        LLM_LOADING = False
    
    except Exception as e:
        LLM_ERROR = f"Erreur lors du chargement du mod√®le LLM avec VLLM: {str(e)}"
        LLM_LOADING = False
        LLM_AVAILABLE = False
        logger.error(LLM_ERROR)

try:
    # Ne lancer le chargement que si n√©cessaire
    if not check_model_cache():
        logger.info("D√©marrage du chargement du mod√®le...")
        LLM_LOADING = True
        threading.Thread(target=load_llm_model_background).start()
    else:
        # Si le mod√®le est en cache, le charger directement en m√©moire
        logger.info("Chargement du mod√®le depuis le cache...")
        LLM_LOADING = True
        threading.Thread(target=load_llm_model_background).start()
except Exception as e:
    logger.error(f"Erreur lors du d√©marrage du thread de chargement LLM: {str(e)}")
    LLM_LOADING = False
    LLM_ERROR = str(e)

def get_llm_status() -> Dict[str, Any]:
    """Retourne le statut du mod√®le LLM"""
    model_name = None
    if LLM_TOKENIZER is not None:
        model_name = MODEL_NAME
    
    return {
        "available": LLM_AVAILABLE,
        "loading": LLM_LOADING,
        "error": LLM_ERROR,
        "model_loaded": LLM_MODEL is not None and LLM_TOKENIZER is not None,
        "model_name": model_name,
        "device": MODEL_DEVICE,
        "engine": "VLLM"  # Indiquer qu'on utilise VLLM
    }

# Reste des fonctions de manipulation de donn√©es inchang√©es
def create_dataframe_from_excel_data(excel_data: Dict[str, Any]) -> pd.DataFrame:
    """Convertit les donn√©es Excel en DataFrame pandas"""
    headers = excel_data.get("headers", [])
    rows = excel_data.get("rows", [])
    
    logger.info(f"Cr√©ation DataFrame: {len(rows)} lignes, {len(headers)} colonnes")
    
    # Cr√©er un DataFrame
    df = pd.DataFrame(rows, columns=headers)
    
    # Convertir les types de donn√©es si possible
    for col in df.columns:
        # Essayer de convertir en num√©rique
        try:
            original_type = df[col].dtype
            df[col] = pd.to_numeric(df[col])
            if original_type != df[col].dtype:
                logger.info(f"Colonne '{col}' convertie en {df[col].dtype}")
        except (ValueError, TypeError):
            # Si √ßa √©choue, essayer de convertir en datetime avec format='mixed'
            try:
                original_type = df[col].dtype
                df[col] = pd.to_datetime(df[col], format='mixed')
                if original_type != df[col].dtype:
                    logger.info(f"Colonne '{col}' convertie en datetime")
            except (ValueError, TypeError):
                # Sinon laisser en string
                pass
    
    logger.info(f"DataFrame cr√©√© avec succ√®s. Types des colonnes importantes: "
                f"'Order Date': {df['Order Date'].dtype if 'Order Date' in df.columns else 'N/A'}, "
                f"'Units Sold': {df['Units Sold'].dtype if 'Units Sold' in df.columns else 'N/A'}")
    
    return df

def generate_python_code(query: str, excel_data: Dict[str, Any]) -> str:
    """G√©n√®re du code Python pour r√©pondre √† la requ√™te en utilisant VLLM"""
    if not LLM_AVAILABLE or LLM_MODEL is None or LLM_TOKENIZER is None:
        raise Exception("Le mod√®le LLM n'est pas disponible")
    
    # Cr√©er le prompt
    headers = excel_data.get("headers", [])
    rows = excel_data.get("rows", [])
    row_count = excel_data.get("row_count", 0)
    
    # Ajouter des informations sur le type de donn√©es pour chaque colonne
    df = create_dataframe_from_excel_data(excel_data)
    column_types = df.dtypes.to_dict()
    column_info = []
    
    for col, dtype in column_types.items():
        column_info.append(f"- {col}: {dtype}")
    
    # Construire le prompt
    prompt = f"""{SYSTEM_PROMPT}

## Structure du DataFrame
Les donn√©es sont d√©j√† charg√©es dans un DataFrame pandas appel√© `df` avec les colonnes suivantes:
{', '.join(headers)}

## Types de donn√©es pour chaque colonne:
{chr(10).join(column_info)}

## Informations sur les donn√©es
- Nombre de lignes: {row_count}
- Nombre de colonnes: {len(headers)}

## Exemples de donn√©es (2 premi√®res lignes):
```
{df.head(2).to_string()}
```

## Requ√™te:
{query}

√âcris un code Python utilisant pandas qui r√©pond √† cette requ√™te. Le code doit:
1. Utiliser le DataFrame 'df' d√©j√† d√©fini
2. Effectuer les op√©rations n√©cessaires
3. Imprimer le r√©sultat clairement
4. Les colonnes de type datetime ont d√©j√† √©t√© converties, NE PAS les reconvertir avec pd.to_datetime()
5. Utiliser directement les op√©rations de comparaison sur ces colonnes

G√©n√®re uniquement le code Python:
```python
"""

    try:
        # Configuration des param√®tres de g√©n√©ration pour VLLM
        sampling_params = SamplingParams(
            temperature=TEMPERATURE,
            max_tokens=MAX_NEW_TOKENS,
            stop=["```"],  # Arr√™ter lorsqu'on atteint la fin du bloc de code
        )
        
        # G√©n√©rer la r√©ponse avec VLLM
        logger.info(f"G√©n√©ration de code avec VLLM pour la requ√™te: {query}")
        outputs = LLM_MODEL.generate(prompt, sampling_params)
        
        # R√©cup√©rer le texte g√©n√©r√©
        generated_text = outputs[0].outputs[0].text
        
        logger.info(f"ü¶æ R√©ponse g√©n√©r√©e par le mod√®le via VLLM : {generated_text}")
        
        # Extraire le code Python
        python_code = extract_python_code(generated_text)
        
        # Ajouter l'import de pandas si n√©cessaire
        if "import pandas" not in python_code:
            python_code = "import pandas as pd\n\n" + python_code
        
        return python_code
    
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration du code Python avec VLLM: {str(e)}")
        raise Exception(f"Erreur lors de la g√©n√©ration du code Python: {str(e)}")

def extract_python_code(text: str) -> str:
    """Extrait le code Python d'une r√©ponse"""
    # Chercher le code entre les balises de code
    pattern = r"```python\s*(.*?)\s*```"
    match = re.search(pattern, text, re.DOTALL)
    
    if match:
        return match.group(1).strip()
    
    # Si pas de balises, prendre tout le texte
    return text.strip()

# Le reste du code reste inchang√©...
def execute_python_code(code: str, excel_data: Dict[str, Any]) -> Dict[str, Any]:
    """Ex√©cute le code Python g√©n√©r√© et retourne le r√©sultat avec √©ventuellement des donn√©es de visualisation"""
    # Garder la r√©trocompatibilit√© avec le syst√®me de visualisation bas√© sur des images
    visualization_path = '/tmp/visualization.png'
    has_visualization = False
    visualization_base64 = None
    visualization_data = None
    has_structured_data = False
    
    # Supprimer toute visualisation pr√©c√©dente
    if os.path.exists(visualization_path):
        os.remove(visualization_path)
    
    try:
        logger.info("=== EX√âCUTION CODE PYTHON ===")
        
        # Cr√©er un DataFrame √† partir des donn√©es Excel
        df = create_dataframe_from_excel_data(excel_data)
        
        # Nettoyer le code g√©n√©r√© pour √©viter les erreurs de syntaxe
        clean_code = code.replace("```python", "").replace("```", "").strip()
        
        # Pr√©parer les imports n√©cessaires
        imports = "import pandas as pd\nimport json\n"
        
        # V√©rifier si le code contient des r√©f√©rences √† visualization_data
        interactive_visualization = 'visualization_data' in clean_code
        
        # V√©rifier si le code fait r√©f√©rence √† des visualisations matplotlib (r√©trocompatibilit√©)
        legacy_visualization = any(x in clean_code for x in ['plt.', 'sns.', '.plot(', '.hist(', 'savefig'])
        
        if interactive_visualization:
            logger.info("Donn√©es structur√©es pour visualisation interactive d√©tect√©es dans le code")
        elif legacy_visualization:
            logger.info("Visualisation matplotlib obsol√®te d√©tect√©e dans le code - mode de compatibilit√©")
        
        # Assembler le code final
        if "import pandas" not in clean_code:
            final_code = imports + "\n" + clean_code
        else:
            final_code = clean_code
        
        logger.info(f"Code √† ex√©cuter:\n{final_code}")
        
        # Capturer la sortie standard
        output = io.StringIO()
        
        # Ex√©cuter le code avec le DataFrame
        try:
            logger.info("Tentative d'ex√©cution...")
            with contextlib.redirect_stdout(output):
                # Cr√©er un environnement d'ex√©cution
                exec_globals = {
                    'pd': pd, 
                    'df': df, 
                    'plt': plt, 
                    'sns': sns,
                    'np': np,
                    'json': json
                }
                exec(final_code, exec_globals)
            
            # R√©cup√©rer la sortie
            result = output.getvalue()
            logger.info(f"Ex√©cution r√©ussie! R√©sultat: {result}")
            
            # V√©rifier si des donn√©es structur√©es ont √©t√© g√©n√©r√©es
            if 'visualization_data' in exec_globals:
                has_structured_data = True
                visualization_data = exec_globals['visualization_data']
                logger.info(f"Donn√©es structur√©es extraites: {json.dumps(visualization_data, cls=PandasJSONEncoder)}")
            
            # R√©trocompatibilit√©: v√©rifier si une visualisation matplotlib a √©t√© g√©n√©r√©e
            if os.path.exists(visualization_path):
                logger.info("Visualisation matplotlib d√©tect√©e dans /tmp/visualization.png")
                has_visualization = True
                with open(visualization_path, 'rb') as img_file:
                    visualization_base64 = base64.b64encode(img_file.read()).decode('utf-8')
                    
                # Facultatif: supprimer le fichier apr√®s l'avoir lu
                os.remove(visualization_path)
            
            return {
                "success": True,
                "code": clean_code,
                "result": result,
                "has_visualization": has_visualization,
                "visualization": visualization_base64,
                "has_structured_data": has_structured_data,
                "visualization_data": visualization_data,
                "error": None
            }
        
        except Exception as exec_e:
            logger.error(f"Erreur d'ex√©cution: {str(exec_e)}")
            
            # Si l'erreur est li√©e au format de date, r√©essayer avec format='mixed'
            if "time data" in str(exec_e) and "doesn't match format" in str(exec_e):
                logger.info("D√©tection erreur format de date. Correction avec format='mixed'...")
                
                # Modifier le code pour utiliser format='mixed'
                fixed_code = re.sub(
                    r"pd\.to_datetime\(([^)]+)\)",
                    r"pd.to_datetime(\1, format='mixed')",
                    final_code
                )
                
                logger.info(f"Code corrig√©:\n{fixed_code}")
                
                # R√©essayer avec le nouveau code
                output = io.StringIO()
                with contextlib.redirect_stdout(output):
                    exec(fixed_code, exec_globals)
                
                # R√©cup√©rer la sortie
                result = output.getvalue()
                logger.info(f"Ex√©cution avec format='mixed' r√©ussie! R√©sultat: {result}")
                
                # V√©rifier si des donn√©es structur√©es ont √©t√© g√©n√©r√©es apr√®s correction
                if 'visualization_data' in exec_globals:
                    has_structured_data = True
                    visualization_data = exec_globals['visualization_data']
                    logger.info(f"Donn√©es structur√©es extraites apr√®s correction: {json.dumps(visualization_data, cls=PandasJSONEncoder)}")
                
                # R√©trocompatibilit√©: v√©rifier si une visualisation a √©t√© g√©n√©r√©e apr√®s correction
                if os.path.exists(visualization_path):
                    logger.info("Visualisation matplotlib d√©tect√©e apr√®s correction")
                    has_visualization = True
                    with open(visualization_path, 'rb') as img_file:
                        visualization_base64 = base64.b64encode(img_file.read()).decode('utf-8')
                        
                    # Facultatif: supprimer le fichier apr√®s l'avoir lu
                    os.remove(visualization_path)
                
                return {
                    "success": True,
                    "code": fixed_code,
                    "result": result,
                    "has_visualization": has_visualization,
                    "visualization": visualization_base64,
                    "has_structured_data": has_structured_data,
                    "visualization_data": visualization_data,
                    "error": None
                }
            else:
                # Pour les autres types d'erreurs
                return {
                    "success": False,
                    "code": final_code,
                    "result": f"L'ex√©cution du code a √©chou√©: {str(exec_e)}",
                    "has_visualization": False,
                    "visualization": None,
                    "has_structured_data": False,
                    "visualization_data": None,
                    "error": str(exec_e)
                }
    
    except Exception as e:
        logger.error(f"Erreur g√©n√©rale: {str(e)}")
        return {
            "success": False,
            "code": code,
            "result": f"Erreur lors de l'ex√©cution: {str(e)}",
            "has_visualization": False,
            "visualization": None,
            "has_structured_data": False,
            "visualization_data": None,
            "error": str(e)
        }
    finally:
        # S'assurer que toutes les figures matplotlib sont ferm√©es
        plt.close('all')
        logger.info("=== FIN EX√âCUTION CODE PYTHON ===")

def analyze_with_llm(query: str, excel_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Analyse les donn√©es Excel avec un LLM et du code Python g√©n√©r√©
    Peut g√©n√©rer des visualisations interactives ou statiques selon le contexte
    
    Args:
        query: Requ√™te utilisateur en langage naturel
        excel_data: Donn√©es Excel (headers, rows, etc.)
        
    Returns:
        R√©sultat de l'analyse avec donn√©es de visualisation structur√©es ou image base64
    """
    try:
        # V√©rifier que le mod√®le est charg√©
        if not LLM_AVAILABLE or LLM_MODEL is None:
            return {
                "success": False,
                "error": "Le mod√®le LLM n'est pas disponible ou n'est pas charg√©"
            }
        
        # D√©tecter si la requ√™te pourrait n√©cessiter une visualisation
        visualization_keywords = [
            "graphique", "graph", "plot", "visualise", "visualiser", "visualisation",
            "affiche", "montre", "repr√©sente", "tendance", "√©volution", "historique",
            "comparer", "comparaison", "r√©partition", "distribution", "courbe", "histogramme",
            "camembert", "diagramme", "barre", "pie chart", "bar chart", "line chart"
        ]
        
        might_need_visualization = any(keyword in query.lower() for keyword in visualization_keywords)
        
        if might_need_visualization:
            logger.info(f"La requ√™te '{query}' pourrait n√©cessiter une visualisation")
        
        # G√©n√©rer le code Python
        python_code = generate_python_code(query, excel_data)
        
        # Ex√©cuter le code Python
        result = execute_python_code(python_code, excel_data)
        
        # Construire la r√©ponse en incluant les informations de visualisation
        response = {
            "success": result["success"],
            "code": result["code"],
            "result": result["result"],
            "error": result["error"],
            # R√©trocompatibilit√©: visualisation matplotlib/seaborn
            "has_visualization": result.get("has_visualization", False),
            "visualization": result.get("visualization"),
            # Nouvelles donn√©es structur√©es pour visualisations interactives
            "has_structured_data": result.get("has_structured_data", False),
            "visualization_data": result.get("visualization_data")
        }
        
        return response
    
    except Exception as e:
        logger.error(f"Erreur lors de l'analyse avec LLM: {str(e)}")
        return {
            "success": False,
            "error": str(e),
            "has_visualization": False,
            "visualization": None
        }
    
def generate_excel_modification(query: str, excel_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    G√©n√®re des commandes pour modifier Excel bas√©es sur une requ√™te en langage naturel
    
    Args:
        query: Requ√™te utilisateur en langage naturel (ex: "change le prix en B5 √† 150")
        excel_data: Donn√©es Excel (headers, rows, etc.)
        
    Returns:
        Commandes de modification Excel
    """
    if not LLM_AVAILABLE or LLM_MODEL is None or LLM_TOKENIZER is None:
        raise Exception("Le mod√®le LLM n'est pas disponible")
    
    headers = excel_data.get("headers", [])
    rows = excel_data.get("rows", [])
    
    # Construire le prompt
    prompt = f"""Tu es un assistant qui g√©n√®re des commandes pour modifier des fichiers Excel.
Bas√© sur la demande de l'utilisateur, g√©n√®re un objet JSON qui contient les commandes n√©cessaires.

## Structure du fichier Excel
Les donn√©es ont les colonnes suivantes:
{', '.join(headers)}

## Exemples de donn√©es (2 premi√®res lignes):
```{pd.DataFrame(rows[:2], columns=headers).to_string()}```
## Types de commandes disponibles:
1. Pour mettre √† jour une cellule: {{"command": "update_cell", "cell": "A1", "value": 100}}
2. Pour ex√©cuter une formule: {{"command": "execute_formula", "cell": "C5", "formula": "=SUM(C1:C4)"}}
3. Pour mettre √† jour une plage: {{"command": "update_range", "start_cell": "A1", "values": [[1, 2], [3, 4]]}}

## Requ√™te de l'utilisateur:
{query}

R√©ponds uniquement avec l'objet JSON appropri√© sans explications, commentaires, backticks ou formatage suppl√©mentaire:
"""

    try:
        # Configuration des param√®tres de g√©n√©ration pour VLLM
        sampling_params = SamplingParams(
            temperature=0.1,
            max_tokens=500,
        )
        
        # G√©n√©rer la r√©ponse avec VLLM
        logger.info(f"G√©n√©ration de commandes Excel pour la requ√™te: {query}")
        outputs = LLM_MODEL.generate(prompt, sampling_params)
        
        # R√©cup√©rer le texte g√©n√©r√©
        generated_text = outputs[0].outputs[0].text
        
        logger.info(f"Commandes g√©n√©r√©es: {generated_text}")
        
        # Essayer d'extraire un JSON valide - VERSION CORRIG√âE
        try:
            # Nettoyer le texte pour s'assurer qu'il contient un JSON valide
            json_text = generated_text.strip()
            
            # Supprimer les backticks et les balises markdown
            json_text = re.sub(r'```(json)?|```', '', json_text, flags=re.IGNORECASE)
            
            # Suppression des espaces blancs au d√©but et √† la fin
            json_text = json_text.strip()
            
            logger.info(f"JSON nettoy√©: {json_text}")
            
            # Analyser le JSON
            command = json.loads(json_text)
            
            return {
                "success": True,
                "command": command,
                "source_query": query
            }
        except json.JSONDecodeError as e:
            logger.error(f"Erreur de d√©codage JSON: {str(e)}")
            
            # Tentative de derni√®re chance: essayer d'extraire manuellement le JSON
            try:
                # Recherche de patterns avec regex pour extraire les valeurs
                cell_pattern = r'"cell":\s*"([A-Z0-9]+)"'
                value_pattern = r'"value":\s*"([^"]+)"'
                command_pattern = r'"command":\s*"([^"]+)"'
                
                cell_match = re.search(cell_pattern, json_text)
                value_match = re.search(value_pattern, json_text)
                command_match = re.search(command_pattern, json_text)
                
                if cell_match and value_match and command_match:
                    cell = cell_match.group(1)
                    value = value_match.group(1)
                    command_type = command_match.group(1)
                    
                    # Construire manuellement la commande
                    command = {
                        "command": command_type,
                        "cell": cell,
                        "value": value
                    }
                    
                    logger.info(f"JSON reconstruit manuellement: {command}")
                    
                    return {
                        "success": True,
                        "command": command,
                        "source_query": query
                    }
            except Exception as regex_error:
                logger.error(f"Tentative de reconstruction JSON √©chou√©e: {str(regex_error)}")
            
            # Si toutes les tentatives √©chouent
            return {
                "success": False,
                "error": f"Le mod√®le n'a pas g√©n√©r√© de JSON valide: {str(e)}",
                "generated_text": generated_text
            }
        
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration des commandes Excel: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }